{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63bd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 9987 images d'entrainement de chats.\n",
      "Nous avons 1248 images de validation de chats.\n",
      "Nous avons 1248 images de test de chats.\n"
     ]
    }
   ],
   "source": [
    "# Avant de lancer la construction du modèle CNN basique on étudie les données disponibles \n",
    "import os \n",
    "X_train_cat = os.listdir('clean_dataset/train/cat')\n",
    "X_val_cat = os.listdir('clean_dataset/validation/cat')\n",
    "X_test_cat = os.listdir('clean_dataset/test/cat')\n",
    "print(\"Nous avons \" + str(len(X_train_cat)) + \" images d'entrainement de chats.\")\n",
    "print(\"Nous avons \" + str(len(X_val_cat)) + \" images de validation de chats.\")\n",
    "print(\"Nous avons \" + str(len(X_test_cat)) + \" images de test de chats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c74f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 9985 images d'entrainement de chiens.\n",
      "Nous avons 1248 images de validation de chiens.\n",
      "Nous avons 1248 images de test de chiens.\n"
     ]
    }
   ],
   "source": [
    "X_train_dog = os.listdir('clean_dataset/train/dog')\n",
    "X_val_dog = os.listdir('clean_dataset/validation/dog')\n",
    "X_test_dog = os.listdir('clean_dataset/test/dog')\n",
    "print(\"Nous avons \" + str(len(X_train_dog)) + \" images d'entrainement de chiens.\")\n",
    "print(\"Nous avons \" + str(len(X_val_dog)) + \" images de validation de chiens.\")\n",
    "print(\"Nous avons \" + str(len(X_test_dog)) + \" images de test de chiens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies utiles \n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a78cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De même que pour la régression logistique, une étape de preprocessing est nécessaire. \n",
    "# Elle permettra de standardiser les dimensions des images et de normaliser les valeurs des pixels. \n",
    "# En accord avec l'architecture VGG16, nous utiliserons des images de 224*224*3. \n",
    "# Pour cela on instancie la méthode ImageDataGenerator de Keras.preprocessing qui permet de normaliser les valeurs de pixels. \n",
    "# On utilise cette méthode car elle permettra dans un autre modèle de réaliser de la data augmentation online.\n",
    "\n",
    "preproc = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e336c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19972 images belonging to 2 classes.\n",
      "Found 2496 images belonging to 2 classes.\n",
      "Found 2496 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# A l'aide de la fonction flow_from_directory() qui nécessite que la structure des dossiers soit celle présentée dans le rapport, \n",
    "# Nous allons pouvoir lire les images directement depuis leurs dossiers respectifs.\n",
    "# Cette méthode permet de fixer la taille des images avec l'argument target_size\n",
    "# Elle créera des batch d'images. \n",
    "# Un batch est caractérisé par sa taille et définit le nombre d'images à traiter par le modèle \n",
    "# avant de mettre à jour les poids du modèle. Une valeur commune de batch est 32 ou 64.\n",
    "# L'avantage d'utiliser flow_from_directory est qu'il infère les labels en se basant sur le nom du dossier.\n",
    "train_set = preproc.flow_from_directory('clean_dataset/train/',\n",
    "                                        class_mode = 'binary',\n",
    "                                        batch_size = 64,\n",
    "                                        target_size = (224, 224))\n",
    "\n",
    "validation_set = preproc.flow_from_directory('clean_dataset/validation',\n",
    "                                             class_mode = 'binary',\n",
    "                                             batch_size = 64,\n",
    "                                             target_size = (224, 224))\n",
    "\n",
    "test_set = preproc.flow_from_directory('clean_dataset/test',\n",
    "                                       class_mode = 'binary', \n",
    "                                       batch_size = 64, \n",
    "                                       target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c1bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fois les données préparer on peut définir le modèle basique\n",
    "# Cette fois on rajouter aussi des couche de dropout\n",
    "# La dropout regularisation permet de réduire l'overfitting observée\n",
    "\n",
    "def basic_cnnx3(): \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # On doit compiler le modèle en spécifiant le solver = algorithme utilisé pour minimiser l'erreur de prédiction\n",
    "    # Les valeurs de learning rate et du momentum sont choisies en accord avec les hyperparamètre de VGG16 \n",
    "    solver = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=solver, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06537254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit la fonction plot_perf() qui enregistrera deux graphiques d'accuracy et de loss pour le\n",
    "# set d'entrainement et de validation.\n",
    "# On précise que history.history contient les différentes métriques de performances réalisées. \n",
    "# Il s'agit de la loss et de l'accuracy\n",
    "\n",
    "def plot_perf(history): \n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # On regarde l'évolution en fonction des epochs \n",
    "    epochs = range(1, len(acc)+1)\n",
    "    \n",
    "    # On plot l'accuracy de l'entrainement et de la validation par epoch\n",
    "    plt.plot(epochs, acc, 'bo', label='Train_Acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label=\"Val_Acc\")\n",
    "    plt.title('Accuracy sur Train et Validation')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    filename1 = \"Train_Val_Acc_CNN_Dropout\"\n",
    "    plt.savefig(filename1 + '_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Train_Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label=\"Val_Loss\" )\n",
    "    plt.title('Loss sur Train et Validation')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    filename2 = \"Train_Val_Loss_CNN_Dropout\"\n",
    "    plt.savefig(filename2 + '_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d899de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créer une fonction qui regroupe les précédente et qui permet de lancer toutes les opérations.\n",
    "def launch_learning(): \n",
    "    \n",
    "    # On définit le modèle\n",
    "    model = basic_cnnx3()\n",
    "    \n",
    "    # On fit le modèle sur les données d'apprentissages et on donne les données de validation\n",
    "    # history contient alors les valeurs de loss et d'accuracy\n",
    "    # Le paramètre verbose permet d'afficher le temps passé par epoch, et l'accuracy et la loss\n",
    "    history = model.fit(train_set, \n",
    "                       validation_data=validation_set, \n",
    "                       epochs=20, \n",
    "                       verbose=1)\n",
    "    \n",
    "    # On évalue le modèle sur le jeux de données test\n",
    "    # Par défaut le paramètre setps est None. L'évaluation prendra en compte tous les batch avant de s'arrêter.\n",
    "    evaluation = model.evaluate(test_set,\n",
    "                                batch_size=64,\n",
    "                                verbose=1)\n",
    "    print(model.metrics_names, evaluation)\n",
    "    \n",
    "    # On enregistre le modèle\n",
    "    filename=\"CNN_Dropout.h5\"\n",
    "    model.save(filename)\n",
    "    \n",
    "    plot_perf(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b76afdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 444s 1s/step - loss: 0.6920 - accuracy: 0.5381 - val_loss: 0.6723 - val_accuracy: 0.5978\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 454s 1s/step - loss: 0.6673 - accuracy: 0.5859 - val_loss: 0.6477 - val_accuracy: 0.6130\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 454s 1s/step - loss: 0.6448 - accuracy: 0.6181 - val_loss: 0.6135 - val_accuracy: 0.6627\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 453s 1s/step - loss: 0.6247 - accuracy: 0.6398 - val_loss: 0.6023 - val_accuracy: 0.6823\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 454s 1s/step - loss: 0.5926 - accuracy: 0.6791 - val_loss: 0.5565 - val_accuracy: 0.7224\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 451s 1s/step - loss: 0.5675 - accuracy: 0.6984 - val_loss: 0.5394 - val_accuracy: 0.7392\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 452s 1s/step - loss: 0.5527 - accuracy: 0.7134 - val_loss: 0.5409 - val_accuracy: 0.7175\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 458s 1s/step - loss: 0.5272 - accuracy: 0.7347 - val_loss: 0.4958 - val_accuracy: 0.7516\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 455s 1s/step - loss: 0.5065 - accuracy: 0.7508 - val_loss: 0.4945 - val_accuracy: 0.7484\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 452s 1s/step - loss: 0.4913 - accuracy: 0.7615 - val_loss: 0.4921 - val_accuracy: 0.7560\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 452s 1s/step - loss: 0.4707 - accuracy: 0.7779 - val_loss: 0.4716 - val_accuracy: 0.7624\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 455s 1s/step - loss: 0.4505 - accuracy: 0.7885 - val_loss: 0.4581 - val_accuracy: 0.7885\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 457s 1s/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.4381 - val_accuracy: 0.7945\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 459s 1s/step - loss: 0.4110 - accuracy: 0.8128 - val_loss: 0.4366 - val_accuracy: 0.7921\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 458s 1s/step - loss: 0.3928 - accuracy: 0.8249 - val_loss: 0.4241 - val_accuracy: 0.8069\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 455s 1s/step - loss: 0.3749 - accuracy: 0.8335 - val_loss: 0.4256 - val_accuracy: 0.8013\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 459s 1s/step - loss: 0.3486 - accuracy: 0.8468 - val_loss: 0.4483 - val_accuracy: 0.7857\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 458s 1s/step - loss: 0.3295 - accuracy: 0.8597 - val_loss: 0.4208 - val_accuracy: 0.8109\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 460s 1s/step - loss: 0.3057 - accuracy: 0.8702 - val_loss: 0.4187 - val_accuracy: 0.8169\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 460s 1s/step - loss: 0.2905 - accuracy: 0.8798 - val_loss: 0.4173 - val_accuracy: 0.8101\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 0.4586 - accuracy: 0.7985\n",
      "['loss', 'accuracy'] [0.45862600207328796, 0.7984775900840759]\n"
     ]
    }
   ],
   "source": [
    "launch_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a29685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
