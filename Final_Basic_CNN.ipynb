{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Bqmit9bn6g",
        "outputId": "a8471ad7-4494-4305-af6b-494d6354b89a"
      },
      "id": "J7Bqmit9bn6g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdoJJTInLBSa",
        "outputId": "80a8b49b-1d80-48f4-c63e-b978ac8a4381"
      },
      "id": "TdoJJTInLBSa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 16 13:45:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "paPb1MdcMWAC"
      },
      "id": "paPb1MdcMWAC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ad5676",
      "metadata": {
        "id": "f6ad5676"
      },
      "outputs": [],
      "source": [
        "# Import des librairies utiles \n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "#from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "585dd644",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "585dd644",
        "outputId": "4e1c1ead-cd72-443c-c296-62e0259e7b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nous avons 9987 images d'entrainement de chats.\n",
            "Nous avons 1248 images de validation de chats.\n",
            "Nous avons 1248 images de test de chats.\n"
          ]
        }
      ],
      "source": [
        "# Avant de lancer la construction du modèle CNN basique on étudie les données disponibles \n",
        "import os \n",
        "X_train_cat = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/train/cat')\n",
        "X_val_cat = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/validation/cat')\n",
        "X_test_cat = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/test/cat')\n",
        "print(\"Nous avons \" + str(len(X_train_cat)) + \" images d'entrainement de chats.\")\n",
        "print(\"Nous avons \" + str(len(X_val_cat)) + \" images de validation de chats.\")\n",
        "print(\"Nous avons \" + str(len(X_test_cat)) + \" images de test de chats.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "326cdc0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "326cdc0a",
        "outputId": "3fd5f838-eee9-44bc-9bba-4c146f87c765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nous avons 9985 images d'entrainement de chiens.\n",
            "Nous avons 1248 images de validation de chiens.\n",
            "Nous avons 1248 images de test de chiens.\n"
          ]
        }
      ],
      "source": [
        "X_train_dog = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/train/dog')\n",
        "X_val_dog = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/validation/dog')\n",
        "X_test_dog = os.listdir('drive/MyDrive/Interface_E2/clean_dataset/test/dog')\n",
        "print(\"Nous avons \" + str(len(X_train_dog)) + \" images d'entrainement de chiens.\")\n",
        "print(\"Nous avons \" + str(len(X_val_dog)) + \" images de validation de chiens.\")\n",
        "print(\"Nous avons \" + str(len(X_test_dog)) + \" images de test de chiens.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6080f5df",
      "metadata": {
        "id": "6080f5df"
      },
      "outputs": [],
      "source": [
        "# De même que pour la régression logistique, une étape de preprocessing est nécessaire. \n",
        "# Elle permettra de standardiser les dimensions des images et de normaliser les valeurs des pixels. \n",
        "# En accord avec l'architecture VGG16, nous utiliserons des images de 224*224*3. \n",
        "# Pour cela on instancie la méthode ImageDataGenerator de Keras.preprocessing qui permet de normaliser les valeurs de pixels. \n",
        "# On utilise cette méthode car elle permettra dans un autre modèle de réaliser de la data augmentation online.\n",
        "preproc = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349e20d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "349e20d5",
        "outputId": "6477e291-1547-4808-8967-a81ef0a559e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19972 images belonging to 2 classes.\n",
            "Found 2496 images belonging to 2 classes.\n",
            "Found 2496 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# A l'aide de la fonction flow_from_directory() qui nécessite que la structure des dossiers soit celle présentée dans le rapport, \n",
        "# Nous allons pouvoir lire les images directement depuis leurs dossiers respectifs.\n",
        "# Cette méthode permet de fixer la taille des images avec l'argument target_size\n",
        "# Elle créera des batch d'images. \n",
        "# Un batch est caractérisé par sa taille et définit le nombre d'images à traiter par le modèle \n",
        "# avant de mettre à jour les poids du modèle. Une valeur commune de batch est 32 ou 64.\n",
        "# L'avantage d'utiliser flow_from_directory est qu'il infère les labels en se basant sur le nom du dossier.\n",
        "train_set = preproc.flow_from_directory('drive/MyDrive/Interface_E2/clean_dataset/train/',\n",
        "                                        class_mode = 'binary',\n",
        "                                        batch_size = 64,\n",
        "                                        target_size = (224, 224))\n",
        "\n",
        "validation_set = preproc.flow_from_directory('drive/MyDrive/Interface_E2/clean_dataset/validation',\n",
        "                                             class_mode = 'binary',\n",
        "                                             batch_size = 64,\n",
        "                                             target_size = (224, 224))\n",
        "\n",
        "test_set = preproc.flow_from_directory('drive/MyDrive/Interface_E2/clean_dataset/test',\n",
        "                                       class_mode = 'binary', \n",
        "                                       batch_size = 64, \n",
        "                                       target_size = (224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3528611f",
      "metadata": {
        "id": "3528611f"
      },
      "outputs": [],
      "source": [
        "# Une fois les données préparer on peut définir le modèle basique\n",
        "\n",
        "def basic_cnn(): \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  # On doit compiler le modèle en spécifiant le solver = algorithme utilisé pour minimiser l'erreur de prédiction\n",
        "  # Les valeurs de learning rate et du momentum sont choisies en accord avec les hyperparamètre de VGG16 \n",
        "  solver = SGD(learning_rate=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=solver, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aec2bfb",
      "metadata": {
        "id": "8aec2bfb"
      },
      "outputs": [],
      "source": [
        "# On définit la fonction plot_perf() qui enregistrera deux graphiques d'accuracy et de loss pour le\n",
        "# set d'entrainement et de validation.\n",
        "# On précise que history.history contient les différentes métriques de performances réalisées. \n",
        "# Il s'agit de la loss et de l'accuracy\n",
        "\n",
        "def plot_perf(history): \n",
        "    \n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    # On regarde l'évolution en fonction des epochs \n",
        "    epochs = range(len(acc))\n",
        "    \n",
        "    # On plot l'accuracy de l'entrainement et de la validation par epoch\n",
        "    plt.plot(epochs, acc, color=\"blue\", label='Train')\n",
        "    plt.plot(epochs, val_acc, color=\"orange\", label=\"Val\")\n",
        "    plt.title('Accuracy sur Train et Validation')\n",
        "    #plt.ylim(yrange)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    \n",
        "    filename1 = \"Train_Val_Acc_BasicCNN\"\n",
        "    plt.savefig(filename1 + '_plot.png')\n",
        "    plt.close()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, color=\"blue\", label='Train')\n",
        "    plt.plot(epochs, val_loss, color=\"orange\", label=\"Val\" )\n",
        "    plt.title('Loss sur Train et Validation')\n",
        "    #plt.ylim(yrange)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    filename2 = \"Train_Val_Loss_BasicCNN\"\n",
        "    plt.savefig(filename2 + '_plot.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6764a98c",
      "metadata": {
        "id": "6764a98c"
      },
      "outputs": [],
      "source": [
        "# On créer une fonction qui regroupe les précédente et qui permet de lancer toutes les opérations.\n",
        "def launch_learning(): \n",
        "    \n",
        "    # On définit le modèle\n",
        "    model = basic_cnn()\n",
        "    \n",
        "    # On fit le modèle sur les données d'apprentissages et on donne les données de validation\n",
        "    # history contient alors les valeurs de loss et d'accuracy\n",
        "    # Le paramètre verbose permet d'afficher le temps passé par epoch, et l'accuracy et la loss\n",
        "    history = model.fit(train_set, \n",
        "                       validation_data=validation_set, \n",
        "                       epochs=25, \n",
        "                       verbose=1)\n",
        "    \n",
        "    # On évalue le modèle sur le jeux de données test\n",
        "    # Par défaut le paramètre setps est None. L'évaluation prendra en compte tous les batch avant de s'arrêter.\n",
        "    evaluation = model.evaluate(test_set,\n",
        "                                batch_size=64,\n",
        "                                verbose=1)\n",
        "    print(model.metrics_names, evaluation)\n",
        "    filename=\"Basic_CNN.sav\"\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "    plot_perf(history)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcfc838",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfcfc838",
        "outputId": "2f1245d6-cb3d-4102-c500-b96120db5fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "313/313 [==============================] - 84s 262ms/step - loss: 0.7065 - accuracy: 0.5307 - val_loss: 0.6831 - val_accuracy: 0.5244\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 78s 251ms/step - loss: 0.6736 - accuracy: 0.5844 - val_loss: 0.6645 - val_accuracy: 0.6030\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.6577 - accuracy: 0.6148 - val_loss: 0.6629 - val_accuracy: 0.6094\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.6593 - accuracy: 0.6120 - val_loss: 0.6664 - val_accuracy: 0.6078\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 77s 247ms/step - loss: 0.6549 - accuracy: 0.6211 - val_loss: 0.6552 - val_accuracy: 0.6298\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 77s 247ms/step - loss: 0.6482 - accuracy: 0.6294 - val_loss: 0.6484 - val_accuracy: 0.6258\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 78s 250ms/step - loss: 0.6414 - accuracy: 0.6395 - val_loss: 0.6618 - val_accuracy: 0.6018\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.6353 - accuracy: 0.6452 - val_loss: 0.6409 - val_accuracy: 0.6350\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 77s 247ms/step - loss: 0.6340 - accuracy: 0.6451 - val_loss: 0.6450 - val_accuracy: 0.6374\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 78s 250ms/step - loss: 0.6223 - accuracy: 0.6536 - val_loss: 0.6266 - val_accuracy: 0.6538\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.6133 - accuracy: 0.6609 - val_loss: 0.6219 - val_accuracy: 0.6454\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.5990 - accuracy: 0.6741 - val_loss: 0.6476 - val_accuracy: 0.6310\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.5914 - accuracy: 0.6836 - val_loss: 0.6051 - val_accuracy: 0.6635\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.5833 - accuracy: 0.6934 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 76s 244ms/step - loss: 0.5654 - accuracy: 0.7023 - val_loss: 0.6797 - val_accuracy: 0.6290\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.5423 - accuracy: 0.7237 - val_loss: 0.5920 - val_accuracy: 0.6775\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.5294 - accuracy: 0.7338 - val_loss: 0.5892 - val_accuracy: 0.6787\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.5029 - accuracy: 0.7565 - val_loss: 0.5622 - val_accuracy: 0.7035\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 77s 247ms/step - loss: 0.4843 - accuracy: 0.7671 - val_loss: 0.5958 - val_accuracy: 0.6887\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.4701 - accuracy: 0.7759 - val_loss: 0.5416 - val_accuracy: 0.7236\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.4252 - accuracy: 0.8083 - val_loss: 0.5547 - val_accuracy: 0.7135\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.3932 - accuracy: 0.8264 - val_loss: 0.5520 - val_accuracy: 0.7264\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 78s 248ms/step - loss: 0.3553 - accuracy: 0.8487 - val_loss: 0.5448 - val_accuracy: 0.7312\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 77s 248ms/step - loss: 0.3248 - accuracy: 0.8646 - val_loss: 0.5693 - val_accuracy: 0.7280\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.2953 - accuracy: 0.8819 - val_loss: 0.5480 - val_accuracy: 0.7304\n",
            "39/39 [==============================] - 1005s 26s/step - loss: 0.5716 - accuracy: 0.7248\n",
            "['loss', 'accuracy'] [0.5716073513031006, 0.7247596383094788]\n"
          ]
        }
      ],
      "source": [
        "launch_learning()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}