{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGtq8_YFhy8s",
        "outputId": "bed0b55d-5440-4bae-b793-db02bd527560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import des librairies utiles \n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "2iD0AAMzh2U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_list = os.listdir(\"/content/gdrive/MyDrive/Interface_E2/clean_dataset/train/cat\")\n",
        "dog_list = os.listdir(\"/content/gdrive/MyDrive/Interface_E2/clean_dataset/train/dog\")\n",
        "print(\"Le nombre d'images d'entrainement de chat est de : \" + str(len(cat_list)))\n",
        "print(\"Le nombre d'images d'entrainement de chien est de : \" + str(len(dog_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izuxAnAgiU_2",
        "outputId": "bfa3504c-a25b-4564-ea9b-4cef68376fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le nombre d'images d'entrainement de chat est de : 9987\n",
            "Le nombre d'images d'entrainement de chien est de : 9985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En raison de limitations computationnelles nous ne prendrons que 5000 images par catégories pour l'entrainement \n",
        "cat_train = cat_list[:5000]\n",
        "dog_train = dog_list[:5000]\n",
        "print(\"Pour la catégorie chat on utilisera \" + str(len(cat_train)) + \" images.\")\n",
        "print(\"Pour la catégorie chien on utilisera \" + str(len(dog_train)) + \" images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyfdZa1hiaFZ",
        "outputId": "3fcd9ece-861c-40d6-9e91-3a7421bcb635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pour la catégorie chat on utilisera 5000 images.\n",
            "Pour la catégorie chien on utilisera 5000 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actuellement nous avons deux liste séparées que nous devons réunir en une unique liste de données d'entrainement. \n",
        "# On utilise la méthode extend() qui concatènera les deux liste à la suite \n",
        "# On utilisera donc np.random.shuffle() pour randomiser le jeu de données d'entrainement. \n",
        "train_list = []\n",
        "train_list.extend(cat_train)\n",
        "train_list.extend(dog_train)\n",
        "np.random.shuffle(train_list)"
      ],
      "metadata": {
        "id": "LeBD6u-oiwC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie la nature de train_list obtenue et on s'assure de la randomisation des données en visualisant les 10 premiers éléments de la liste\n",
        "train_list[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vu353Lri0mB",
        "outputId": "b9893dca-945b-407f-c31c-73a856582c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog.2281.jpg',\n",
              " 'cat.2515.jpg',\n",
              " 'dog.10606.jpg',\n",
              " 'cat.5807.jpg',\n",
              " 'cat.3751.jpg',\n",
              " 'dog.11873.jpg',\n",
              " 'cat.11045.jpg',\n",
              " 'dog.10377.jpg',\n",
              " 'dog.3951.jpg',\n",
              " 'dog.8626.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On remarque que cette liste contient uniquement le nom du fichier. \n",
        "# Le modèle de régression logistique le n'accepte que des valeurs numériques et non pas des images au format .jpg. \n",
        "# Pour convertir les images au format numérique, il faut considérer 2 éléments qui sont la taille de l'image (hauteur, largeur) et l'encodage de la couleur au format RGB donc 3 canaux. \n",
        "# Or, on a observé durant la phase de nettoyage que les images n'avaient pas de taille standard. \n",
        "# Il est donc nécessaire d'implémenter une étape de redimensionnement des images de sortes qu'elles aient toute une taille standard. \n",
        "# Il est admis que plus une image a une taille réduite plus l'apprentissage est rapide. On décide donc de redimensionner les images au format 100x100x3 \n",
        "# On initialise donc un vecteur qui aura pour dimension (10000, 100*100*3). \n",
        "# En effet, les 10000 images d'entrainements seront assignées à ce vecteur une fois qu'elles auront été redimensionnées. \n",
        "X_train = np.zeros((10000, 100*100*3))"
      ],
      "metadata": {
        "id": "XS3_8NcTi3vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On doit redimensionner l'ensemble des images d'entrainement à l'aide de la fonction resize() et crop()\n",
        "# La fonction redim prend en paramètre ke chemin de l'image et la taille et renvoie une image redimensionnée depuis le centre avec la taille spécifiée\n",
        "def redim(image_path, size): \n",
        "  img = Image.open(image_path)\n",
        "  img = img.resize((size+1, size+1))\n",
        "  x_center = img.width/2\n",
        "  y_center = img.height/2\n",
        "  size = size/2\n",
        "  redim_img = img.crop((x_center-size, y_center-size, x_center+size, y_center+size))\n",
        "  return redim_img "
      ],
      "metadata": {
        "id": "d4YJo7I-i8aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On applique la fonction redim() à l'ensemble des images dans train_list\n",
        "# Une fois redimensionnées, on les transforme en vecteur grâce à la fonction np.array()\n",
        "# Puis on remplace le vecteur vide de l'image dans X_train par le vecteur de l'image ainsi prétraitée. \n",
        "for i, image_name in enumerate(train_list): \n",
        "  if image_name.split(\".\")[0] == \"dog\":\n",
        "    path = \"/content/gdrive/MyDrive/Interface_E2/clean_dataset/train/dog\"\n",
        "  else: \n",
        "    path = \"/content/gdrive/MyDrive/Interface_E2/clean_dataset/train/cat\"\n",
        "  image_path = f'{path}/{image_name}'\n",
        "  resized_img = redim(image_path, 100)\n",
        "  resized_array_img = np.array(resized_img).reshape(-1)\n",
        "  X_train[i] = resized_array_img"
      ],
      "metadata": {
        "id": "Z1lwCsQK_bq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie les dimensions du vecteur qui devraient être de 10 000 par 30 000\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHiPd9IujJDE",
        "outputId": "47001f5b-55b6-4015-b974-d48c41376396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 30000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie que les vecteurs d'images ont bien été remplacé dans le vecteur vide\n",
        "# On observe les valeurs de X_train[0]\n",
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5tTXf2ky3i",
        "outputId": "9c4af380-d9ac-4a79-81eb-01888e23a280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([165., 153., 137., ..., 133., 119.,  88.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On normalize les images. Cette étape consiste à diviser par 255 l'ensemble du vecteur. \n",
        "# Ainsi, on on obtient des vecteurs avec des valeurs de pixels par image comprise entre 0 et 255. \n",
        "# Cette étape permet notamment de réduire la durée d'apprentissage tout en maintenant le rapport entre les différentes valeurs de pixels\n",
        "X_train = X_train/255"
      ],
      "metadata": {
        "id": "sQbLn4oxlEUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nos données d'entrainement sont maintenant prête. \n",
        "# Cependant, nous sommes dans un cas d'apprentissage supervisé, il nous faut donc récolter les labels de chaque image présente dans X_train\n",
        "# Pour cela on doit passer d'une liste de nom de fichier à une liste de label. \n",
        "# Nos images contiennent dans leur nom de fichier le label. \n",
        "# On utilise donc la méthode split() et la méthode de list comprehension en Python \n",
        "# On rappelle que la catégorie chat = 0 et la catégorie chien = 1 \n",
        "Y_train = np.array([0 if name.split(\".\")[0]==\"cat\" else 1 for name in train_list])"
      ],
      "metadata": {
        "id": "B3TFVlq9lqyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie que les labels obtenu correspondent bien aux images. \n",
        "# On visualise les 10 premiers labels de Y_train et vérifie leur bonne correspondance avec les 10 premières images de X_train. \n",
        "Y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcLeKermW2E",
        "outputId": "00aa2c1d-03b4-4c34-b9fb-59ea0a9e1119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie que Y_train contient bien autant de label que nous avons d'images d'entrainement soit : 10 000\n",
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzgc4VammfH",
        "outputId": "20bcd09d-6ecc-4705-f6a4-520eef194e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# À présent nos images d'entrainement ont été converties en vecteur de pixels, les valeurs des pixels ont été normalisées\n",
        "# et les labels ont été récupérés : notre jeu d'entrainement est prêt pour alimenter le modèle\n",
        "model = LogisticRegression(max_iter=1000, solver = 'liblinear', penalty='l2', verbose=1)\n"
      ],
      "metadata": {
        "id": "2T6w1LiEm1S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On peut mettre un timer pour avoir une estimation du temps de l'apprentissage \n",
        "start = dt.now()\n",
        "model.fit(X_train, Y_train)\n",
        "running_secs = (dt.now()-start).seconds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrC7Wdq67XqN",
        "outputId": "c28f0f44-547c-443e-9669-afcc8898f9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On sauvegarde le modèle à l'aide de pickle \n",
        "filename = \"Log_Reg_10000.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "qPAomDf0AU8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On évalue les performances du modèle sur le jeu de données d'entrainement \n",
        "train_pred = model.predict(X_train)\n",
        "cm = confusion_matrix(train_pred, Y_train)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drHJIy1j7zZl",
        "outputId": "dddbac08-95d6-4b78-c1be-8fd46889d1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4991,    4],\n",
              "       [   9, 4996]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On plot la matrice de confusion \n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Dv3pfmkSChrR",
        "outputId": "97902b78-3712-4ea5-f90b-52127d70376d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ee78fc9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On doit maintenant évaluer le modèle sur le set de validation. \n",
        "# Etant donné qu'on a 10 000 images d'entrainement, on validera sur un échantillon de 2000 images soit 20%\n",
        "# On aura donc 1000 images de chat et 1000 images de chien à classifier\n",
        "val_list_dog = os.listdir(\"/content/gdrive/MyDrive/Interface_E2/clean_dataset/validation/dog\")\n",
        "val_list_cat = os.listdir(\"/content/gdrive/MyDrive/Interface_E2/clean_dataset/validation/cat\")\n",
        "print(\"Le nombre d'images de validation de chat est de : \" + str(len(val_list_cat)))\n",
        "print(\"Le nombre d'images de validation de chien est de : \" + str(len(val_list_dog)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjUxJ3l6CuoH",
        "outputId": "40d6b5b4-62d0-45c3-a316-de72bec81663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le nombre d'images de validation de chat est de : 1248\n",
            "Le nombre d'images de validation de chien est de : 1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On ne sélectionne que 1000 images dans chaque catégorie puis on créer une nouvelle liste comme précédemment \n",
        "val_list_dog = val_list_dog[:1000]\n",
        "val_list_cat = val_list_cat[:1000]\n",
        "val_list = []\n",
        "val_list.extend(val_list_dog)\n",
        "val_list.extend(val_list_cat)"
      ],
      "metadata": {
        "id": "q59c7p25D5nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On vérifie que val_list contiennent bien 2000 images \n",
        "len(val_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8sWhjetEnQO",
        "outputId": "22bd093f-eb65-4866-8b6b-54132db436b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On recréer la matrice des images avec les données de validation \n",
        "X_val = np.zeros((2000, 100*100*3))"
      ],
      "metadata": {
        "id": "74W-ZntMEtiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, image_name in enumerate(val_list):\n",
        "    if image_name.split(\".\")[0] == \"dog\":\n",
        "        path =  \"/content/gdrive/MyDrive/Interface_E2/clean_dataset/validation/dog\"\n",
        "    else:\n",
        "        path =  \"/content/gdrive/MyDrive/Interface_E2/clean_dataset/validation/cat\"\n",
        "    image_path = f'{path}/{image_name}'\n",
        "    crp_img = redim(image_path,100)\n",
        "    crp_arr = np.array(crp_img).reshape(-1)\n",
        "    X_val[i] = crp_arr"
      ],
      "metadata": {
        "id": "4AwFdmpmE8bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On normalize les valeurs des pixels \n",
        "X_val = X_val/255"
      ],
      "metadata": {
        "id": "6veNHciXFawk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On récupère les lables des images de validation \n",
        "val_labels = np.array([0 if name.split(\".\")[0]==\"cat\" else 1 for name in val_list])"
      ],
      "metadata": {
        "id": "fUJQ68UHFfex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On lance les prédiction sur le jeu de validation et on calcule la matrice de confusion\n",
        "val_pred = model.predict(X_val)\n",
        "cm_val = confusion_matrix(val_pred, val_labels)\n",
        "cm_val "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFPsWt1RFtTV",
        "outputId": "c10d97ce-8bd5-44cb-a7e0-471dd34171dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[602, 506],\n",
              "       [398, 494]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On plot la matrice de confusion sur les données de validation \n",
        "sns.heatmap(cm_val, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "5mdf7QWMGEuo",
        "outputId": "ce1a08ff-3118-4fa1-f0f0-d2d70daaaf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ee7995490>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En complément de la matrice de confusion on peut analyser la précision, le recall et le f1-score. \n",
        "# L'ensemble de ces métriques peuvent être obtenues avec la méthode classification_report()\n",
        "# On enregistre le rapport dans un dataframe qu'on peut exposert au format csv \n",
        "report = classification_report(val_labels, val_pred, output_dict=True)"
      ],
      "metadata": {
        "id": "Mniu5PRTG5sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(report).transpose()"
      ],
      "metadata": {
        "id": "v4PfmybVKI7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pUxSs5_VKVqp",
        "outputId": "0e24fbcb-a609-4872-de32-abfbc62096c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              precision  recall  f1-score   support\n",
              "0              0.543321   0.602  0.571157  1000.000\n",
              "1              0.553812   0.494  0.522199  1000.000\n",
              "accuracy       0.548000   0.548  0.548000     0.548\n",
              "macro avg      0.548566   0.548  0.546678  2000.000\n",
              "weighted avg   0.548566   0.548  0.546678  2000.000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ad310b4-f9c9-45b1-b78f-a6aa5c65282a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.543321</td>\n",
              "      <td>0.602</td>\n",
              "      <td>0.571157</td>\n",
              "      <td>1000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.553812</td>\n",
              "      <td>0.494</td>\n",
              "      <td>0.522199</td>\n",
              "      <td>1000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.548000</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.548000</td>\n",
              "      <td>0.548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.548566</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.546678</td>\n",
              "      <td>2000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.548566</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.546678</td>\n",
              "      <td>2000.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ad310b4-f9c9-45b1-b78f-a6aa5c65282a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ad310b4-f9c9-45b1-b78f-a6aa5c65282a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ad310b4-f9c9-45b1-b78f-a6aa5c65282a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('classification_report.csv')"
      ],
      "metadata": {
        "id": "zjPY1R_TKXC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interprétation : \n",
        "# Précision : \n",
        "# Parmi les 1000 chats et 1000 chiens que le modèle a prédit seulement 54.3% étaient vraiment des chats et 55.4% étaient vraiment des chien. \n",
        "# Recall : Parmi les 1000 images qui étaient vraiment des chats, le modèle a prédit correctement à 60.2% les chats \n",
        "# Parmi les 1000 images qui étaient vraiment des chiens, le modèle a prédit correctement à 49.4% les chiens.\n",
        "# F1-Score : Cette valeur est assez éloignée de 1 : Le modèle a donc réaliser une prédiction pauvre. "
      ],
      "metadata": {
        "id": "51AWvXm-Kv7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un autre indicateur de performance qu'on peut étudier est la courbe ROC\n",
        "no_learn = [0 for _ in range(len(val_labels))]"
      ],
      "metadata": {
        "id": "w8D3lxlqMyp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # On prédit la probabilité des images de validation \n",
        "learn_probs = model.predict_proba(X_val)\n",
        "\n",
        "# On ne garde que les probabilité de la classe 1 \n",
        "learn_probs = learn_probs[:, 1]\n",
        "\n",
        "# On calcule les score \n",
        "nl_auc = roc_auc_score(val_labels, no_learn)\n",
        "lr_auc = roc_auc_score(val_labels, learn_probs)\n",
        "\n",
        "# Résume les score \n",
        "print(\"No Skill: ROC AUC=%.3f\" % (nl_auc))\n",
        "print(\"Logistic: ROC AUC=%.3f\" % (lr_auc))\n",
        "\n",
        "# Calcule les courbes ROC \n",
        "ns_fpr, ns_tpr, _ = roc_curve(val_labels, no_learn)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(val_labels, learn_probs)\n",
        "\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label=\"No Skill\")\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "plt.xlabel('Taux de faux positifs')\n",
        "plt.ylabel('Taux de vrai positifs')\n",
        "plt.legend()\n",
        "plotfile = 'Courbe_ROC_Reg_Log'\n",
        "plt.savefig(plotfile + '_plot.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "iKizlMcQOCdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02679df1-6c94-4577-9a84-1cb37555af6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Skill: ROC AUC=0.500\n",
            "Logistic: ROC AUC=0.569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On peut essayer d'améliorer ce modèle soit en testant la cross validation \n",
        "# Soit en faisant de la data augmentation. \n"
      ],
      "metadata": {
        "id": "vjBZBCQzMaOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}